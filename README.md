# Reproducing InfoLM test results

This is a repository containing notebooks for generating reproducible results for testing [InfoLM](https://arxiv.org/abs/2112.01589),
[BaryScore](https://arxiv.org/abs/2108.12463) (TBA), [DepthScore](https://arxiv.org/abs/2103.12711) (TBA) metrics used
for the verification of the equivalence of these metrics and their [`torchmetics`](https://github.com/Lightning-AI/metrics)
counterparts.

The more information and code for these three aforementiond metrics can be found in the [original repo](https://github.com/PierreColombo/nlg_eval_via_simi_measures).
